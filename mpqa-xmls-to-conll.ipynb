{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_and_sent_number(df, last_sentence):\n",
    "    sentence_number = last_sentence\n",
    "    sentence = ''\n",
    "    new_df = pd.DataFrame(columns=['ix', 'token', 'is_modal', 'is_prej', 'modal_type', 'sentence_number'])\n",
    "    first_token = -1\n",
    "    modal_count = 0\n",
    "    for i, row in df.iterrows():\n",
    "        sentence += row['token'] + ' '\n",
    "        df.at[i, 'sentence_number'] = sentence_number\n",
    "        if row['is_modal'] in ['S', 'B']:\n",
    "            modal_count += 1\n",
    "        if row['token'] in ['.', '?', '!']:\n",
    "            metadata = pd.DataFrame(data={'ix': [None, '#', '#', '#'], \n",
    "                                          'token': [None, 'Sent_number = ', 'sentence_text = ', 'modal_count = '], \n",
    "                                          'is_modal': [None, sentence_number, sentence, modal_count], \n",
    "                                          'is_prej': [None, None, None, None], 'modal_type': [None, None, None, None], \n",
    "                                          'sentence_number': [None, None, None, None]})\n",
    "            new_df = pd.concat([new_df, metadata, df.iloc[first_token+1:i]],sort=False).reset_index(drop=True)\n",
    "    \n",
    "            sentence_number += 1\n",
    "            sentence = ''\n",
    "            first_token = i\n",
    "            modal_count = 0            \n",
    "            \n",
    "    return new_df, sentence_number\n",
    "\n",
    "def get_elements_ids_and_tokens(file_content):\n",
    "    tokens = {}\n",
    "    for row in file_content:\n",
    "        try:\n",
    "            if re.search('mark id=', row):\n",
    "                component_id = re.findall('id=\\\"(\\w+\\_*\\d+)\\\"', row)[0]\n",
    "\n",
    "                tokens[component_id] = re.findall('#sTok(\\d+)', row)\n",
    "        except:\n",
    "            if not re.search('#sTok(\\d+)', row):\n",
    "                continue\n",
    "            else:\n",
    "                raise Exception(file, row)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_BIOSE(token_list, col):\n",
    "    for token_group in token_list:\n",
    "        if len(token_group) == 1:\n",
    "            df.at[df['ix'] == int(token_group[0]), col] = 'S'\n",
    "        else:\n",
    "            df.at[df['ix'] == int(token_group[0]), col] = 'B'\n",
    "            df.at[df['ix'] == int(token_group[-1]), col] = 'E'\n",
    "            for token in token_group[1:-1]:\n",
    "                df.at[df['ix'] == int(token), col] = 'I'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_modal_type(element_ids, lines):\n",
    "    modal_fine_grain = ''\n",
    "    modal_coarse_grain = ''\n",
    "    for modal_id, tokens in element_ids.items():\n",
    "        if 'modal' in modal_id:\n",
    "            for line in lines:\n",
    "                if re.search(modal_id, line):\n",
    "                    modal_fine_grain = re.findall('value=\\\"(\\w+)\\\"', line)[0]\n",
    "            if modal_fine_grain in ['deontic', 'buletic', 'teleological', 'buletic_teleological']:\n",
    "                modal_coarse_grain = 'priority'\n",
    "            elif modal_fine_grain in ['epistemic_circumstantial', 'epistemic']:\n",
    "                modal_coarse_grain = 'epistemic'\n",
    "            elif modal_fine_grain in ['ability_circumstantial', 'ability']:\n",
    "                modal_coarse_grain = 'ability'\n",
    "            elif modal_fine_grain in ['circumstantial']:\n",
    "                modal_coarse_grain = 'circumstantial'\n",
    "            if modal_coarse_grain:\n",
    "                for token in tokens:\n",
    "                    df.at[df['ix'] == int(token), 'modal_type'] = str((modal_coarse_grain, modal_fine_grain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_span(element_ids, lines):\n",
    "    modals_with_spans = {}\n",
    "    for element_id, tokens in element_ids.items():\n",
    "        if 'modal' in element_id:\n",
    "            span_particles = []\n",
    "            for line in lines:\n",
    "                if re.search(element_id, line):\n",
    "                    try:\n",
    "                        particle = re.findall('href=\\\"\\#(\\w+)\\\"', line)[0]\n",
    "                        \n",
    "                        span_particles.append(element_ids[particle])\n",
    "                        span_tokens = [t for tokens in span_particles for t in tokens]\n",
    "                        for token in span_tokens:\n",
    "                            df.at[df['ix'] == int(token), 'span'] = element_id\n",
    "                    except:\n",
    "                        raise Exception(line, re.findall('href=\\\"\\#(\\w+)\\\"', line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prejacent_tokens(element_ids) -> list:\n",
    "    prejacent_tokens = []\n",
    "    for other_id, tokens in element_ids.items():\n",
    "        if 'other' in other_id:\n",
    "            for line in lines:\n",
    "                if re.search(other_id + '\\\"', line) and 'prejacent' in line:\n",
    "                    if tokens not in prejacent_tokens: \n",
    "                        prejacent_tokens.append(tokens)\n",
    "    return prejacent_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [files for root, dirs, files in os.walk('./gme-conll/')]\n",
    "docs = ['.'.join(file.split('.')[1:-1]) for files in docs for file in files]\n",
    "\n",
    "last_sentence = 0\n",
    "\n",
    "for doc in tqdm(docs):\n",
    "    if len(doc) < 3:\n",
    "        continue\n",
    "    for root, dirs, files in os.walk('./gme-conll/'):\n",
    "        for file in files:\n",
    "            if doc in file:\n",
    "                df = pd.read_csv(os.path.join(root,file), sep='\\t', usecols=[0,1,2,3,4,5, 6], \n",
    "                                 names=['ix', 'token', 'is_modal', 'is_prej', 'modal_type', 'sentence_number', 'span'])\n",
    "    for root, dirs, files in os.walk('./xmls/'):\n",
    "        for file in files:\n",
    "            if doc in file:\n",
    "                if 'mark.xml' in file:\n",
    "                    with open(os.path.join(root,file), 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        element_ids = get_elements_ids_and_tokens(lines)\n",
    "                        modal_tokens = [v for k, v in element_ids.items() if 'modal' in k]\n",
    "                        tag_BIOSE(modal_tokens, 'is_modal')\n",
    "                if 'mark_label.xml' in file:\n",
    "                    with open(os.path.join(root,file), 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        prej_tokens = get_prejacent_tokens(element_ids)\n",
    "                        tag_BIOSE(prej_tokens, 'is_prej')\n",
    "                if 'mark_modal_id.xml' in file:\n",
    "                    with open(os.path.join(root,file), 'r') as f:\n",
    "                        lines = f.readlines() \n",
    "                        tag_span(element_ids, lines)\n",
    "                if '.mark_subtype_' in file:\n",
    "                    with open(os.path.join(root,file), 'r') as f:\n",
    "                        lines = f.readlines()\n",
    "                        update_modal_type(element_ids, lines)\n",
    "\n",
    "    df, last_sentence = add_metadata_and_sent_number(df, last_sentence)\n",
    "\n",
    "    df.to_csv('./tagged_gme_conll/tmp/{}.csv'.format(doc), sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
